{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMP2RsCv3eWixHo0w18q13x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amna-Ghulam-Nabie/Assignment-3/blob/master/IRAssignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rxqMHjpi1zk",
        "outputId": "989b2753-d601-4fb8-b97c-9d0a3f51daf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created dummy 'documents' directory with example files.\n",
            "Loaded 3 documents\n",
            "Building index using hybrid method...\n",
            "Building TF-IDF index...\n",
            "Building BM25 index...\n",
            "Building Boolean index...\n",
            "Index built successfully!\n",
            "Index saved to ir_index.pkl\n",
            "Enter search query: Amna is a Student\n",
            "\n",
            "================================================================================\n",
            "Top 3 results for query: 'Amna is a Student'\n",
            "================================================================================\n",
            "\n",
            "Rank: 1\n",
            "Document: doc1.txt\n",
            "Score: 0.0000\n",
            "Content: This is the first document. It talks about information retrieval.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank: 2\n",
            "Document: doc2.txt\n",
            "Score: 0.0000\n",
            "Content: The second document discusses search engines and ranking algorithms.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank: 3\n",
            "Document: doc3.txt\n",
            "Score: 0.0000\n",
            "Content: Information technology is a vast field. Retrieval of data is crucial.\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from typing import List, Dict, Tuple\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "# Core NLP imports\n",
        "try:\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "    from sklearn.metrics.pairwise import cosine_similarity\n",
        "    import nltk\n",
        "    from nltk.corpus import stopwords\n",
        "    from nltk.stem import PorterStemmer\n",
        "    from nltk.tokenize import word_tokenize\n",
        "except ImportError:\n",
        "    print(\"Installing required packages...\")\n",
        "    import subprocess\n",
        "    subprocess.check_call([\"pip\", \"install\", \"scikit-learn\", \"nltk\", \"rank-bm25\"])\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "    from sklearn.metrics.pairwise import cosine_similarity\n",
        "    import nltk\n",
        "    from nltk.corpus import stopwords\n",
        "    from nltk.stem import PorterStemmer\n",
        "    from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download NLTK data\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "    nltk.data.find('tokenizers/punkt_tab') # Add this line to check for punkt_tab\n",
        "except LookupError:\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    nltk.download('punkt_tab', quiet=True) # Add this line to download punkt_tab\n",
        "\n",
        "\n",
        "class TextPreprocessor:\n",
        "    \"\"\"Handles text preprocessing and normalization\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.stemmer = PorterStemmer()\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    def preprocess(self, text: str, stem: bool = True, remove_stopwords: bool = True) -> str:\n",
        "        \"\"\"Preprocess text with tokenization, lowercasing, stemming, and stopword removal\"\"\"\n",
        "        # Lowercase\n",
        "        text = text.lower()\n",
        "\n",
        "        # Remove special characters but keep spaces\n",
        "        text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
        "\n",
        "        # Tokenize\n",
        "        tokens = word_tokenize(text)\n",
        "\n",
        "        # Remove stopwords\n",
        "        if remove_stopwords:\n",
        "            tokens = [t for t in tokens if t not in self.stop_words]\n",
        "\n",
        "        # Stem\n",
        "        if stem:\n",
        "            tokens = [self.stemmer.stem(t) for t in tokens]\n",
        "\n",
        "        return ' '.join(tokens)\n",
        "\n",
        "    def tokenize(self, text: str) -> List[str]:\n",
        "        \"\"\"Tokenize and return list of tokens\"\"\"\n",
        "        processed = self.preprocess(text)\n",
        "        return processed.split()\n",
        "\n",
        "\n",
        "class BM25Retriever:\n",
        "    \"\"\"BM25 ranking algorithm implementation\"\"\"\n",
        "\n",
        "    def __init__(self, k1: float = 1.5, b: float = 0.75):\n",
        "        self.k1 = k1\n",
        "        self.b = b\n",
        "        self.corpus_size = 0\n",
        "        self.avgdl = 0\n",
        "        self.doc_freqs = []\n",
        "        self.idf = {}\n",
        "        self.doc_len = []\n",
        "        self.tokenized_corpus = []\n",
        "\n",
        "    def fit(self, corpus: List[str]):\n",
        "        \"\"\"Build BM25 index from corpus\"\"\"\n",
        "        preprocessor = TextPreprocessor()\n",
        "        self.tokenized_corpus = [preprocessor.tokenize(doc) for doc in corpus]\n",
        "        self.corpus_size = len(corpus)\n",
        "        self.doc_len = [len(doc) for doc in self.tokenized_corpus]\n",
        "        self.avgdl = sum(self.doc_len) / self.corpus_size\n",
        "\n",
        "        # Calculate document frequencies\n",
        "        df = defaultdict(int)\n",
        "        for doc in self.tokenized_corpus:\n",
        "            for word in set(doc):\n",
        "                df[word] += 1\n",
        "\n",
        "        # Calculate IDF\n",
        "        self.idf = {}\n",
        "        for word, freq in df.items():\n",
        "            self.idf[word] = np.log((self.corpus_size - freq + 0.5) / (freq + 0.5) + 1)\n",
        "\n",
        "    def score(self, query: str, doc_id: int) -> float:\n",
        "        \"\"\"Calculate BM25 score for a document given a query\"\"\"\n",
        "        preprocessor = TextPreprocessor()\n",
        "        query_tokens = preprocessor.tokenize(query)\n",
        "        doc = self.tokenized_corpus[doc_id]\n",
        "        doc_len = self.doc_len[doc_id]\n",
        "\n",
        "        score = 0.0\n",
        "        for token in query_tokens:\n",
        "            if token not in self.idf:\n",
        "                continue\n",
        "\n",
        "            # Term frequency in document\n",
        "            tf = doc.count(token)\n",
        "\n",
        "            # BM25 formula\n",
        "            numerator = tf * (self.k1 + 1)\n",
        "            denominator = tf + self.k1 * (1 - self.b + self.b * (doc_len / self.avgdl))\n",
        "            score += self.idf[token] * (numerator / denominator)\n",
        "\n",
        "        return score\n",
        "\n",
        "    def search(self, query: str, top_k: int = 10) -> List[Tuple[int, float]]:\n",
        "        \"\"\"Search and return top-k documents\"\"\"\n",
        "        scores = [(i, self.score(query, i)) for i in range(self.corpus_size)]\n",
        "        scores.sort(key=lambda x: x[1], reverse=True)\n",
        "        return scores[:top_k]\n",
        "\n",
        "\n",
        "class BooleanRetriever:\n",
        "    \"\"\"Boolean retrieval with inverted index\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.inverted_index = defaultdict(set)\n",
        "        self.doc_count = 0\n",
        "\n",
        "    def fit(self, corpus: List[str]):\n",
        "        \"\"\"Build inverted index\"\"\"\n",
        "        preprocessor = TextPreprocessor()\n",
        "        self.doc_count = len(corpus)\n",
        "\n",
        "        for doc_id, doc in enumerate(corpus):\n",
        "            tokens = preprocessor.tokenize(doc)\n",
        "            for token in set(tokens):\n",
        "                self.inverted_index[token].add(doc_id)\n",
        "\n",
        "    def search(self, query: str, top_k: int = 10) -> List[Tuple[int, float]]:\n",
        "        \"\"\"Boolean AND search\"\"\"\n",
        "        preprocessor = TextPreprocessor()\n",
        "        query_tokens = preprocessor.tokenize(query)\n",
        "\n",
        "        if not query_tokens:\n",
        "            return []\n",
        "\n",
        "        # Start with documents containing first term\n",
        "        result_docs = self.inverted_index.get(query_tokens[0], set()).copy()\n",
        "\n",
        "        # AND with remaining terms\n",
        "        for token in query_tokens[1:]:\n",
        "            result_docs &= self.inverted_index.get(token, set())\n",
        "\n",
        "        # Score by number of matching terms (for ranking)\n",
        "        scores = []\n",
        "        for doc_id in result_docs:\n",
        "            score = len(query_tokens)  # All terms matched\n",
        "            scores.append((doc_id, float(score)))\n",
        "\n",
        "        scores.sort(key=lambda x: x[1], reverse=True)\n",
        "        return scores[:top_k]\n",
        "\n",
        "\n",
        "class TfidfRetriever:\n",
        "    \"\"\"TF-IDF based retrieval using cosine similarity\"\"\"\n",
        "\n",
        "    def __init__(self, max_features: int = 10000):\n",
        "        self.vectorizer = TfidfVectorizer(\n",
        "            max_features=max_features,\n",
        "            stop_words='english',\n",
        "            ngram_range=(1, 2)\n",
        "        )\n",
        "        self.tfidf_matrix = None\n",
        "\n",
        "    def fit(self, corpus: List[str]):\n",
        "        \"\"\"Build TF-IDF matrix\"\"\"\n",
        "        self.tfidf_matrix = self.vectorizer.fit_transform(corpus)\n",
        "\n",
        "    def search(self, query: str, top_k: int = 10) -> List[Tuple[int, float]]:\n",
        "        \"\"\"Search using cosine similarity\"\"\"\n",
        "        query_vec = self.vectorizer.transform([query])\n",
        "        similarities = cosine_similarity(query_vec, self.tfidf_matrix).flatten()\n",
        "\n",
        "        # Get top-k indices\n",
        "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
        "        scores = [(int(idx), float(similarities[idx])) for idx in top_indices]\n",
        "\n",
        "        return scores\n",
        "\n",
        "\n",
        "class HybridRetriever:\n",
        "    \"\"\"Combines multiple retrieval strategies\"\"\"\n",
        "\n",
        "    def __init__(self, weights: Dict[str, float] = None):\n",
        "        self.weights = weights or {'tfidf': 0.4, 'bm25': 0.5, 'boolean': 0.1}\n",
        "        self.tfidf = TfidfRetriever()\n",
        "        self.bm25 = BM25Retriever()\n",
        "        self.boolean = BooleanRetriever()\n",
        "\n",
        "    def fit(self, corpus: List[str]):\n",
        "        \"\"\"Fit all retrievers\"\"\"\n",
        "        print(\"Building TF-IDF index...\")\n",
        "        self.tfidf.fit(corpus)\n",
        "        print(\"Building BM25 index...\")\n",
        "        self.bm25.fit(corpus)\n",
        "        print(\"Building Boolean index...\")\n",
        "        self.boolean.fit(corpus)\n",
        "\n",
        "    def search(self, query: str, top_k: int = 10) -> List[Tuple[int, float]]:\n",
        "        \"\"\"Hybrid search combining all strategies\"\"\"\n",
        "        # Get results from each retriever\n",
        "        tfidf_results = dict(self.tfidf.search(query, top_k=50))\n",
        "        bm25_results = dict(self.bm25.search(query, top_k=50))\n",
        "        boolean_results = dict(self.boolean.search(query, top_k=50))\n",
        "\n",
        "        # Normalize scores to [0, 1]\n",
        "        def normalize_scores(results):\n",
        "            if not results:\n",
        "                return {}\n",
        "            max_score = max(results.values()) if results else 1\n",
        "            if max_score == 0:\n",
        "                return {k: 0 for k in results}\n",
        "            return {k: v / max_score for k, v in results.items()}\n",
        "\n",
        "        tfidf_norm = normalize_scores(tfidf_results)\n",
        "        bm25_norm = normalize_scores(bm25_results)\n",
        "        boolean_norm = normalize_scores(boolean_results)\n",
        "\n",
        "        # Combine scores\n",
        "        all_docs = set(tfidf_norm.keys()) | set(bm25_norm.keys()) | set(boolean_norm.keys())\n",
        "        combined_scores = []\n",
        "\n",
        "        for doc_id in all_docs:\n",
        "            score = (\n",
        "                self.weights['tfidf'] * tfidf_norm.get(doc_id, 0) +\n",
        "                self.weights['bm25'] * bm25_norm.get(doc_id, 0) +\n",
        "                self.weights['boolean'] * boolean_norm.get(doc_id, 0)\n",
        "            )\n",
        "            combined_scores.append((doc_id, score))\n",
        "\n",
        "        combined_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "        return combined_scores[:top_k]\n",
        "\n",
        "\n",
        "class IRSystem:\n",
        "    \"\"\"Main Information Retrieval System\"\"\"\n",
        "\n",
        "    def __init__(self, retrieval_method: str = 'hybrid'):\n",
        "        \"\"\"\n",
        "        Initialize IR System\n",
        "\n",
        "        Args:\n",
        "            retrieval_method: 'tfidf', 'bm25', 'boolean', or 'hybrid'\n",
        "        \"\"\"\n",
        "        self.retrieval_method = retrieval_method\n",
        "        self.documents = []\n",
        "        self.doc_ids = []\n",
        "        self.retriever = None\n",
        "        self.is_fitted = False\n",
        "\n",
        "    def load_documents(self, path: str):\n",
        "        \"\"\"Load documents from directory or file\"\"\"\n",
        "        path = Path(path)\n",
        "\n",
        "        if path.is_file():\n",
        "            # Single file\n",
        "            with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "                content = f.read()\n",
        "                self.documents.append(content)\n",
        "                self.doc_ids.append(path.name)\n",
        "\n",
        "        elif path.is_dir():\n",
        "            # Directory of files\n",
        "            for file_path in sorted(path.glob('**/*.txt')):\n",
        "                try:\n",
        "                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "                        content = f.read()\n",
        "                        if content.strip():\n",
        "                            self.documents.append(content)\n",
        "                            self.doc_ids.append(str(file_path.relative_to(path)))\n",
        "                except Exception as e:\n",
        "                    print(f\"Error reading {file_path}: {e}\")\n",
        "\n",
        "        print(f\"Loaded {len(self.documents)} documents\")\n",
        "\n",
        "    def build_index(self):\n",
        "        \"\"\"Build retrieval index\"\"\"\n",
        "        if not self.documents:\n",
        "            raise ValueError(\"No documents loaded. Call load_documents() first.\")\n",
        "\n",
        "        print(f\"Building index using {self.retrieval_method} method...\")\n",
        "\n",
        "        if self.retrieval_method == 'tfidf':\n",
        "            self.retriever = TfidfRetriever()\n",
        "        elif self.retrieval_method == 'bm25':\n",
        "            self.retriever = BM25Retriever()\n",
        "        elif self.retrieval_method == 'boolean':\n",
        "            self.retriever = BooleanRetriever()\n",
        "        elif self.retrieval_method == 'hybrid':\n",
        "            self.retriever = HybridRetriever()\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown retrieval method: {self.retrieval_method}\")\n",
        "\n",
        "        self.retriever.fit(self.documents)\n",
        "        self.is_fitted = True\n",
        "        print(\"Index built successfully!\")\n",
        "\n",
        "    def search(self, query: str, top_k: int = 10) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Search for documents matching the query\n",
        "\n",
        "        Returns:\n",
        "            List of dicts with keys: doc_id, score, content\n",
        "        \"\"\"\n",
        "        if not self.is_fitted:\n",
        "            raise ValueError(\"Index not built. Call build_index() first.\")\n",
        "\n",
        "        results = self.retriever.search(query, top_k=top_k)\n",
        "\n",
        "        output = []\n",
        "        for doc_idx, score in results:\n",
        "            output.append({\n",
        "                'rank': len(output) + 1,\n",
        "                'doc_id': self.doc_ids[doc_idx],\n",
        "                'score': score,\n",
        "                'content': self.documents[doc_idx][:500] + '...' if len(self.documents[doc_idx]) > 500 else self.documents[doc_idx]\n",
        "            })\n",
        "\n",
        "        return output\n",
        "\n",
        "    def save_index(self, filepath: str):\n",
        "        \"\"\"Save index to disk\"\"\"\n",
        "        data = {\n",
        "            'retrieval_method': self.retrieval_method,\n",
        "            'documents': self.documents,\n",
        "            'doc_ids': self.doc_ids,\n",
        "            'retriever': self.retriever\n",
        "        }\n",
        "        with open(filepath, 'wb') as f:\n",
        "            pickle.dump(data, f)\n",
        "        print(f\"Index saved to {filepath}\")\n",
        "\n",
        "    def load_index(self, filepath: str):\n",
        "        \"\"\"Load index from disk\"\"\"\n",
        "        with open(filepath, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "\n",
        "        self.retrieval_method = data['retrieval_method']\n",
        "        self.documents = data['documents']\n",
        "        self.doc_ids = data['doc_ids']\n",
        "        self.retriever = data['retriever']\n",
        "        self.is_fitted = True\n",
        "        print(f\"Index loaded from {filepath}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Example usage\"\"\"\n",
        "    # Create a dummy 'documents' directory and files if they don't exist\n",
        "    docs_dir = Path('documents')\n",
        "    if not docs_dir.exists():\n",
        "        docs_dir.mkdir()\n",
        "        with open(docs_dir / 'doc1.txt', 'w') as f:\n",
        "            f.write(\"This is the first document. It talks about information retrieval.\")\n",
        "        with open(docs_dir / 'doc2.txt', 'w') as f:\n",
        "            f.write(\"The second document discusses search engines and ranking algorithms.\")\n",
        "        with open(docs_dir / 'doc3.txt', 'w') as f:\n",
        "            f.write(\"Information technology is a vast field. Retrieval of data is crucial.\")\n",
        "        print(\"Created dummy 'documents' directory with example files.\")\n",
        "\n",
        "    # Initialize system\n",
        "    ir_system = IRSystem(retrieval_method='hybrid')\n",
        "\n",
        "    # Load documents\n",
        "    # Replace 'documents' with your actual document directory\n",
        "    ir_system.load_documents('documents')\n",
        "\n",
        "    # Build index\n",
        "    ir_system.build_index()\n",
        "\n",
        "    # Save index (optional)\n",
        "    ir_system.save_index('ir_index.pkl')\n",
        "\n",
        "    # Search\n",
        "    query = input(\"Enter search query: \")\n",
        "    results = ir_system.search(query, top_k=5)\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Top {len(results)} results for query: '{query}'\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    for result in results:\n",
        "        print(f\"Rank: {result['rank']}\")\n",
        "        print(f\"Document: {result['doc_id']}\")\n",
        "        print(f\"Score: {result['score']:.4f}\")\n",
        "        print(f\"Content: {result['content']}\")\n",
        "        print(f\"{'-'*80}\\n\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from typing import List, Dict, Tuple\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "# NLP imports\n",
        "try:\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "    from sklearn.metrics.pairwise import cosine_similarity\n",
        "    import nltk\n",
        "    from nltk.corpus import stopwords\n",
        "    from nltk.stem import PorterStemmer\n",
        "    from nltk.tokenize import word_tokenize\n",
        "except ImportError:\n",
        "    import subprocess\n",
        "    subprocess.check_call([\"pip\", \"install\", \"scikit-learn\", \"nltk\", \"rank-bm25\"])\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "    from sklearn.metrics.pairwise import cosine_similarity\n",
        "    import nltk\n",
        "    from nltk.corpus import stopwords\n",
        "    from nltk.stem import PorterStemmer\n",
        "    from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "# Download NLTK\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "    nltk.data.find('tokenizers/punkt_tab')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    nltk.download('punkt_tab', quiet=True)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# TEXT NORMALIZER\n",
        "# ---------------------------------------------------------\n",
        "class TextCleaner:\n",
        "    \"\"\"Handles all text cleaning operations\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.word_stemmer = PorterStemmer()\n",
        "        self.stopword_list = set(stopwords.words('english'))\n",
        "\n",
        "    def clean(self, text_input: str, apply_stem: bool = True, remove_stop: bool = True) -> str:\n",
        "        text_input = text_input.lower()\n",
        "        text_input = re.sub(r'[^a-z0-9\\s]', ' ', text_input)\n",
        "        token_list = word_tokenize(text_input)\n",
        "\n",
        "        if remove_stop:\n",
        "            token_list = [t for t in token_list if t not in self.stopword_list]\n",
        "\n",
        "        if apply_stem:\n",
        "            token_list = [self.word_stemmer.stem(t) for t in token_list]\n",
        "\n",
        "        return ' '.join(token_list)\n",
        "\n",
        "    def tokens(self, text_input: str) -> List[str]:\n",
        "        cleaned = self.clean(text_input)\n",
        "        return cleaned.split()\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# BM25 RANKER\n",
        "# ---------------------------------------------------------\n",
        "class BM25Ranker:\n",
        "    \"\"\"BM25 Ranking Implementation\"\"\"\n",
        "\n",
        "    def __init__(self, k1: float = 1.5, b: float = 0.75):\n",
        "        self.k1_val = k1\n",
        "        self.b_val = b\n",
        "        self.doc_total = 0\n",
        "        self.avg_len = 0\n",
        "        self.doc_frequencies = []\n",
        "        self.idf_map = {}\n",
        "        self.length_list = []\n",
        "        self.token_docs = []\n",
        "\n",
        "    def build(self, corpus_list: List[str]):\n",
        "        cleaner = TextCleaner()\n",
        "        self.token_docs = [cleaner.tokens(doc) for doc in corpus_list]\n",
        "        self.doc_total = len(corpus_list)\n",
        "        self.length_list = [len(doc) for doc in self.token_docs]\n",
        "        self.avg_len = sum(self.length_list) / self.doc_total\n",
        "\n",
        "        df_counter = defaultdict(int)\n",
        "        for doc in self.token_docs:\n",
        "            for word in set(doc):\n",
        "                df_counter[word] += 1\n",
        "\n",
        "        self.idf_map = {}\n",
        "        for word, freq in df_counter.items():\n",
        "            self.idf_map[word] = np.log((self.doc_total - freq + 0.5) /\n",
        "                                        (freq + 0.5) + 1)\n",
        "\n",
        "    def score_doc(self, query_str: str, doc_index: int) -> float:\n",
        "        cleaner = TextCleaner()\n",
        "        q_tokens = cleaner.tokens(query_str)\n",
        "        document = self.token_docs[doc_index]\n",
        "        doc_len = self.length_list[doc_index]\n",
        "\n",
        "        score_total = 0.0\n",
        "\n",
        "        for tok in q_tokens:\n",
        "            if tok not in self.idf_map:\n",
        "                continue\n",
        "\n",
        "            tf_value = document.count(tok)\n",
        "            numerator = tf_value * (self.k1_val + 1)\n",
        "            denominator = tf_value + self.k1_val * (\n",
        "                    1 - self.b_val + self.b_val * (doc_len / self.avg_len)\n",
        "            )\n",
        "            score_total += self.idf_map[tok] * (numerator / denominator)\n",
        "\n",
        "        return score_total\n",
        "\n",
        "    def top(self, query_str: str, top_n: int = 10):\n",
        "        results = [(i, self.score_doc(query_str, i)) for i in range(self.doc_total)]\n",
        "        results.sort(key=lambda x: x[1], reverse=True)\n",
        "        return results[:top_n]\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# BOOLEAN RANKER\n",
        "# ---------------------------------------------------------\n",
        "class BooleanRanker:\n",
        "    \"\"\"Boolean Retrieval Engine\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.inv_map = defaultdict(set)\n",
        "        self.total_docs = 0\n",
        "\n",
        "    def build(self, doc_list: List[str]):\n",
        "        cleaner = TextCleaner()\n",
        "        self.total_docs = len(doc_list)\n",
        "\n",
        "        for d_id, doc in enumerate(doc_list):\n",
        "            tokens = cleaner.tokens(doc)\n",
        "            for word in set(tokens):\n",
        "                self.inv_map[word].add(d_id)\n",
        "\n",
        "    def top(self, query_str: str, top_n: int = 10):\n",
        "        cleaner = TextCleaner()\n",
        "        q_tokens = cleaner.tokens(query_str)\n",
        "\n",
        "        if not q_tokens:\n",
        "            return []\n",
        "\n",
        "        doc_set = self.inv_map.get(q_tokens[0], set()).copy()\n",
        "\n",
        "        for tok in q_tokens[1:]:\n",
        "            doc_set &= self.inv_map.get(tok, set())\n",
        "\n",
        "        ranked = [(idx, float(len(q_tokens))) for idx in doc_set]\n",
        "        ranked.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        return ranked[:top_n]\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# TF-IDF RANKER\n",
        "# ---------------------------------------------------------\n",
        "class TfidfRanker:\n",
        "    \"\"\"TF-IDF Search Engine\"\"\"\n",
        "\n",
        "    def __init__(self, max_feats: int = 10000):\n",
        "        self.vec = TfidfVectorizer(\n",
        "            max_features=max_feats,\n",
        "            stop_words='english',\n",
        "            ngram_range=(1, 2)\n",
        "        )\n",
        "        self.matrix = None\n",
        "\n",
        "    def build(self, doc_list: List[str]):\n",
        "        self.matrix = self.vec.fit_transform(doc_list)\n",
        "\n",
        "    def top(self, query_str: str, top_n: int = 10):\n",
        "        qry = self.vec.transform([query_str])\n",
        "        sims = cosine_similarity(qry, self.matrix).flatten()\n",
        "\n",
        "        idxs = np.argsort(sims)[::-1][:top_n]\n",
        "        return [(int(i), float(sims[i])) for i in idxs]\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# HYBRID RANKER\n",
        "# ---------------------------------------------------------\n",
        "class MixedRanker:\n",
        "    \"\"\"Weighted Hybrid Combination Retriever\"\"\"\n",
        "\n",
        "    def __init__(self, weight_map=None):\n",
        "        self.weight_map = weight_map or {'tfidf': 0.4, 'bm25': 0.5, 'bool': 0.1}\n",
        "        self.tf_module = TfidfRanker()\n",
        "        self.bm_module = BM25Ranker()\n",
        "        self.bool_module = BooleanRanker()\n",
        "\n",
        "    def build(self, docs):\n",
        "        print(\"→ Building TF-IDF model...\")\n",
        "        self.tf_module.build(docs)\n",
        "        print(\"→ Building BM25 model...\")\n",
        "        self.bm_module.build(docs)\n",
        "        print(\"→ Building Boolean model...\")\n",
        "        self.bool_module.build(docs)\n",
        "\n",
        "    def top(self, q, k=10):\n",
        "        tf_res = dict(self.tf_module.top(q, top_n=50))\n",
        "        bm_res = dict(self.bm_module.top(q, top_n=50))\n",
        "        bl_res = dict(self.bool_module.top(q, top_n=50))\n",
        "\n",
        "        def norm(scores):\n",
        "            if not scores:\n",
        "                return {}\n",
        "            m = max(scores.values())\n",
        "            if m == 0:\n",
        "                return {x: 0 for x in scores}\n",
        "            return {d: v / m for d, v in scores.items()}\n",
        "\n",
        "        tf_norm = norm(tf_res)\n",
        "        bm_norm = norm(bm_res)\n",
        "        bl_norm = norm(bl_res)\n",
        "\n",
        "        all_ids = set(tf_norm.keys()) | set(bm_norm.keys()) | set(bl_norm.keys())\n",
        "        final_scores = []\n",
        "\n",
        "        for doc_id in all_ids:\n",
        "            final_val = (\n",
        "                self.weight_map['tfidf'] * tf_norm.get(doc_id, 0) +\n",
        "                self.weight_map['bm25'] * bm_norm.get(doc_id, 0) +\n",
        "                self.weight_map['bool'] * bl_norm.get(doc_id, 0)\n",
        "            )\n",
        "            final_scores.append((doc_id, final_val))\n",
        "\n",
        "        final_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "        return final_scores[:k]\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# MAIN IR SYSTEM\n",
        "# ---------------------------------------------------------\n",
        "class RetrievalCore:\n",
        "    \"\"\"Main IR System Controller\"\"\"\n",
        "\n",
        "    def __init__(self, mode: str = 'hybrid'):\n",
        "        self.mode = mode\n",
        "        self.raw_docs = []\n",
        "        self.file_ids = []\n",
        "        self.engine = None\n",
        "        self.ready = False\n",
        "\n",
        "    def ingest(self, folder_path):\n",
        "        folder_path = Path(folder_path)\n",
        "\n",
        "        if folder_path.is_file():\n",
        "            content = folder_path.read_text(encoding='utf-8', errors='ignore')\n",
        "            self.raw_docs.append(content)\n",
        "            self.file_ids.append(folder_path.name)\n",
        "\n",
        "        elif folder_path.is_dir():\n",
        "            for f in sorted(folder_path.glob('**/*.txt')):\n",
        "                try:\n",
        "                    txt = f.read_text(encoding='utf-8', errors='ignore')\n",
        "                    if txt.strip():\n",
        "                        self.raw_docs.append(txt)\n",
        "                        self.file_ids.append(str(f.relative_to(folder_path)))\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "        print(f\"Loaded {len(self.raw_docs)} files.\")\n",
        "\n",
        "    def create_index(self):\n",
        "        if not self.raw_docs:\n",
        "            raise ValueError(\"No documents found.\")\n",
        "\n",
        "        print(f\"Using search mode: {self.mode}\")\n",
        "\n",
        "        if self.mode == 'tfidf':\n",
        "            self.engine = TfidfRanker()\n",
        "        elif self.mode == 'bm25':\n",
        "            self.engine = BM25Ranker()\n",
        "        elif self.mode == 'boolean':\n",
        "            self.engine = BooleanRanker()\n",
        "        else:\n",
        "            self.engine = MixedRanker()\n",
        "\n",
        "        self.engine.build(self.raw_docs)\n",
        "        self.ready = True\n",
        "        print(\"Index built successfully.\")\n",
        "\n",
        "    def query(self, q, k=10):\n",
        "        if not self.ready:\n",
        "            raise ValueError(\"Index not initialized.\")\n",
        "\n",
        "        results = self.engine.top(q, k)\n",
        "        output = []\n",
        "\n",
        "        for idx, score_val in results:\n",
        "            output.append({\n",
        "                \"rank\": len(output) + 1,\n",
        "                \"file\": self.file_ids[idx],\n",
        "                \"score\": score_val,\n",
        "                \"preview\": self.raw_docs[idx][:500] + \"...\"\n",
        "            })\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# RUNNER\n",
        "# ---------------------------------------------------------\n",
        "def main():\n",
        "    data_path = Path(\"documents\")\n",
        "    if not data_path.exists():\n",
        "        data_path.mkdir()\n",
        "        (data_path / \"doc1.txt\").write_text(\"This document is about information retrieval.\")\n",
        "        (data_path / \"doc2.txt\").write_text(\"This text explains search engines and ranking models.\")\n",
        "        (data_path / \"doc3.txt\").write_text(\"Data retrieval is important in many fields.\")\n",
        "\n",
        "    system = RetrievalCore(mode=\"hybrid\")\n",
        "    system.ingest(\"documents\")\n",
        "    system.create_index()\n",
        "\n",
        "    query_text = input(\"Enter your query: \")\n",
        "    results = system.query(query_text, k=5)\n",
        "\n",
        "    print(\"\\n======================= RESULTS =======================\")\n",
        "    for res in results:\n",
        "        print(f\"Rank: {res['rank']}\")\n",
        "        print(f\"File: {res['file']}\")\n",
        "        print(f\"Score: {res['score']:.4f}\")\n",
        "        print(f\"Preview: {res['preview']}\")\n",
        "        print(\"------------------------------------------------------\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EW0kfvOqTkK",
        "outputId": "ce366937-e004-4b75-9ed7-4af3003c940a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 3 files.\n",
            "Using search mode: hybrid\n",
            "→ Building TF-IDF model...\n",
            "→ Building BM25 model...\n",
            "→ Building Boolean model...\n",
            "Index built successfully.\n",
            "Enter your query: Information Reterival\n",
            "\n",
            "======================= RESULTS =======================\n",
            "Rank: 1\n",
            "File: doc1.txt\n",
            "Score: 0.9000\n",
            "Preview: This is the first document. It talks about information retrieval....\n",
            "------------------------------------------------------\n",
            "Rank: 2\n",
            "File: doc3.txt\n",
            "Score: 0.7069\n",
            "Preview: Information technology is a vast field. Retrieval of data is crucial....\n",
            "------------------------------------------------------\n",
            "Rank: 3\n",
            "File: doc2.txt\n",
            "Score: 0.0000\n",
            "Preview: The second document discusses search engines and ranking algorithms....\n",
            "------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}